version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: mount_isa_services
      POSTGRES_USER: scraper_user
      POSTGRES_PASSWORD: scraper_pass
      POSTGRES_HOST_AUTH_METHOD: trust
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-scripts:/docker-entrypoint-initdb.d
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U scraper_user -d mount_isa_services"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Redis Cache & Message Broker
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Elasticsearch for search and analytics
  elasticsearch:
    image: elasticsearch:8.11.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
      - "9300:9300"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3

  # RabbitMQ for agent communication
  rabbitmq:
    image: rabbitmq:3-management-alpine
    environment:
      RABBITMQ_DEFAULT_USER: scraper_user
      RABBITMQ_DEFAULT_PASS: scraper_pass
    ports:
      - "5672:5672"
      - "15672:15672"  # Management UI
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
    healthcheck:
      test: ["CMD", "rabbitmq-diagnostics", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Main API Service
  api:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql://scraper_user:scraper_pass@postgres:5432/mount_isa_services
      - REDIS_URL=redis://redis:6379/0
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - RABBITMQ_URL=amqp://scraper_user:scraper_pass@rabbitmq:5672/
      - ENVIRONMENT=development
    volumes:
      - .:/app
      - ./logs:/app/logs
      - ./models:/app/models
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      elasticsearch:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
    restart: unless-stopped

  # Celery Worker for background tasks
  celery-worker:
    build:
      context: .
      dockerfile: Dockerfile
    command: celery -A app.core.celery worker --loglevel=info --concurrency=4
    environment:
      - DATABASE_URL=postgresql://scraper_user:scraper_pass@postgres:5432/mount_isa_services
      - REDIS_URL=redis://redis:6379/0
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - RABBITMQ_URL=amqp://scraper_user:scraper_pass@rabbitmq:5672/
      - ENVIRONMENT=development
    volumes:
      - .:/app
      - ./logs:/app/logs
      - ./models:/app/models
    depends_on:
      - postgres
      - redis
      - rabbitmq
    restart: unless-stopped

  # Celery Beat for scheduled tasks
  celery-beat:
    build:
      context: .
      dockerfile: Dockerfile
    command: celery -A app.core.celery beat --loglevel=info
    environment:
      - DATABASE_URL=postgresql://scraper_user:scraper_pass@postgres:5432/mount_isa_services
      - REDIS_URL=redis://redis:6379/0
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - RABBITMQ_URL=amqp://scraper_user:scraper_pass@rabbitmq:5672/
      - ENVIRONMENT=development
    volumes:
      - .:/app
      - ./logs:/app/logs
    depends_on:
      - postgres
      - redis
      - rabbitmq
    restart: unless-stopped

  # Agent Orchestrator
  agent-orchestrator:
    build:
      context: .
      dockerfile: Dockerfile
    command: python -m app.agents.orchestrator
    environment:
      - DATABASE_URL=postgresql://scraper_user:scraper_pass@postgres:5432/mount_isa_services
      - REDIS_URL=redis://redis:6379/0
      - ELASTICSEARCH_URL=http://elasticsearch:9200
      - RABBITMQ_URL=amqp://scraper_user:scraper_pass@rabbitmq:5672/
      - ENVIRONMENT=development
    volumes:
      - .:/app
      - ./logs:/app/logs
      - ./models:/app/models
    depends_on:
      - postgres
      - redis
      - rabbitmq
    restart: unless-stopped

  # Monitoring with Prometheus
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'

  # Grafana for visualization
  grafana:
    image: grafana/grafana:latest
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./monitoring/grafana:/etc/grafana/provisioning
    depends_on:
      - prometheus

volumes:
  postgres_data:
  redis_data:
  elasticsearch_data:
  rabbitmq_data:
  prometheus_data:
  grafana_data: